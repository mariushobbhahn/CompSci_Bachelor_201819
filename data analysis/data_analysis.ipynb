{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis for the bachelor thesis: using the scattering transform for image classification by Marius Hobbhahn (2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Baseline tests: 3 Datasets(VOC, Kitti, toy_data) with additional parameters Batchnorm, Augmentations, Pretrained. Dependant variable is AP = average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VOC</th>\n",
       "      <th>Toy_data</th>\n",
       "      <th>Kitti</th>\n",
       "      <th>Augmentations</th>\n",
       "      <th>Batchnorm</th>\n",
       "      <th>Pretrained</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    VOC  Toy_data  Kitti  Augmentations  Batchnorm  Pretrained  Accuracy\n",
       "0     1         0      0              1          1           1    0.6250\n",
       "1     1         0      0              1          1           1    0.6205\n",
       "2     1         0      0              1          1           1    0.6062\n",
       "3     1         0      0              1          1           1    0.6164\n",
       "4     1         0      0              1          1           1    0.6271\n",
       "5     1         0      0              0          1           1    0.3470\n",
       "6     1         0      0              0          1           1    0.3411\n",
       "7     1         0      0              0          1           1    0.3686\n",
       "8     1         0      0              0          1           1    0.3191\n",
       "9     1         0      0              0          1           1    0.3287\n",
       "10    1         0      0              0          0           1    0.2687\n",
       "11    1         0      0              0          0           1    0.4055\n",
       "12    1         0      0              0          0           1    0.3836\n",
       "13    1         0      0              0          0           1    0.3960\n",
       "14    1         0      0              1          0           1    0.6267\n",
       "15    1         0      0              1          0           1    0.6308\n",
       "16    1         0      0              1          0           1    0.6285\n",
       "17    1         0      0              1          0           1    0.6344\n",
       "18    1         0      0              1          1           0    0.5712\n",
       "19    1         0      0              1          1           0    0.5678\n",
       "20    1         0      0              1          1           0    0.3215\n",
       "21    1         0      0              1          1           0    0.5654\n",
       "22    1         0      0              0          1           0    0.2527\n",
       "23    1         0      0              0          1           0    0.3411\n",
       "24    1         0      0              0          1           0    0.3686\n",
       "25    1         0      0              0          1           0    0.3553\n",
       "26    1         0      0              0          1           0    0.3287\n",
       "27    1         0      0              0          0           0    0.1074\n",
       "28    1         0      0              0          0           0    0.0969\n",
       "29    1         0      0              0          0           0    0.1193\n",
       "..  ...       ...    ...            ...        ...         ...       ...\n",
       "64    0         0      1              1          1           1    0.0990\n",
       "65    0         0      1              1          1           1    0.1267\n",
       "66    0         0      1              1          1           1    0.1154\n",
       "67    0         0      1              1          1           1    0.1117\n",
       "68    0         0      1              0          1           1    0.0279\n",
       "69    0         0      1              0          1           1    0.0232\n",
       "70    0         0      1              0          1           1    0.0242\n",
       "71    0         0      1              0          1           1    0.0222\n",
       "72    0         0      1              0          0           1    0.0300\n",
       "73    0         0      1              0          0           1    0.0176\n",
       "74    0         0      1              0          0           1    0.0422\n",
       "75    0         0      1              0          0           1    0.0386\n",
       "76    0         0      1              1          0           1    0.1104\n",
       "77    0         0      1              1          0           1    0.1351\n",
       "78    0         0      1              1          0           1    0.1293\n",
       "79    0         0      1              1          1           0    0.1121\n",
       "80    0         0      1              1          1           0    0.1351\n",
       "81    0         0      1              1          1           0    0.1136\n",
       "82    0         0      1              1          1           0    0.1014\n",
       "83    0         0      1              0          1           0    0.0250\n",
       "84    0         0      1              0          1           0    0.0250\n",
       "85    0         0      1              0          1           0    0.0458\n",
       "86    0         0      1              0          0           0    0.0202\n",
       "87    0         0      1              0          0           0    0.0676\n",
       "88    0         0      1              0          0           0    0.0165\n",
       "89    0         0      1              0          0           0    0.0036\n",
       "90    0         0      1              1          0           0    0.0665\n",
       "91    0         0      1              1          0           0    0.0438\n",
       "92    0         0      1              1          0           0    0.0423\n",
       "93    0         0      1              1          0           0    0.0466\n",
       "\n",
       "[94 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load and show\n",
    "baselinedf = pd.read_csv('baselines.csv', delimiter=',')\n",
    "baselinedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VOC</th>\n",
       "      <th>Toy_data</th>\n",
       "      <th>Kitti</th>\n",
       "      <th>Augmentations</th>\n",
       "      <th>Batchnorm</th>\n",
       "      <th>Pretrained</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    VOC  Toy_data  Kitti  Augmentations  Batchnorm  Pretrained  Accuracy\n",
       "0     1         0      0              1          1           1    0.6250\n",
       "1     1         0      0              1          1           1    0.6205\n",
       "2     1         0      0              1          1           1    0.6062\n",
       "3     1         0      0              1          1           1    0.6164\n",
       "4     1         0      0              1          1           1    0.6271\n",
       "5     1         0      0              0          1           1    0.3470\n",
       "6     1         0      0              0          1           1    0.3411\n",
       "7     1         0      0              0          1           1    0.3686\n",
       "8     1         0      0              0          1           1    0.3191\n",
       "9     1         0      0              0          1           1    0.3287\n",
       "10    1         0      0              0          0           1    0.2687\n",
       "11    1         0      0              0          0           1    0.4055\n",
       "12    1         0      0              0          0           1    0.3836\n",
       "13    1         0      0              0          0           1    0.3960\n",
       "14    1         0      0              1          0           1    0.6267\n",
       "15    1         0      0              1          0           1    0.6308\n",
       "16    1         0      0              1          0           1    0.6285\n",
       "17    1         0      0              1          0           1    0.6344\n",
       "18    1         0      0              1          1           0    0.5712\n",
       "19    1         0      0              1          1           0    0.5678\n",
       "21    1         0      0              1          1           0    0.5654\n",
       "22    1         0      0              0          1           0    0.2527\n",
       "23    1         0      0              0          1           0    0.3411\n",
       "24    1         0      0              0          1           0    0.3686\n",
       "25    1         0      0              0          1           0    0.3553\n",
       "26    1         0      0              0          1           0    0.3287\n",
       "27    1         0      0              0          0           0    0.1074\n",
       "28    1         0      0              0          0           0    0.0969\n",
       "29    1         0      0              0          0           0    0.1193\n",
       "30    1         0      0              0          0           0    0.1101\n",
       "..  ...       ...    ...            ...        ...         ...       ...\n",
       "64    0         0      1              1          1           1    0.0990\n",
       "65    0         0      1              1          1           1    0.1267\n",
       "66    0         0      1              1          1           1    0.1154\n",
       "67    0         0      1              1          1           1    0.1117\n",
       "68    0         0      1              0          1           1    0.0279\n",
       "69    0         0      1              0          1           1    0.0232\n",
       "70    0         0      1              0          1           1    0.0242\n",
       "71    0         0      1              0          1           1    0.0222\n",
       "72    0         0      1              0          0           1    0.0300\n",
       "73    0         0      1              0          0           1    0.0176\n",
       "74    0         0      1              0          0           1    0.0422\n",
       "75    0         0      1              0          0           1    0.0386\n",
       "76    0         0      1              1          0           1    0.1104\n",
       "77    0         0      1              1          0           1    0.1351\n",
       "78    0         0      1              1          0           1    0.1293\n",
       "79    0         0      1              1          1           0    0.1121\n",
       "80    0         0      1              1          1           0    0.1351\n",
       "81    0         0      1              1          1           0    0.1136\n",
       "82    0         0      1              1          1           0    0.1014\n",
       "83    0         0      1              0          1           0    0.0250\n",
       "84    0         0      1              0          1           0    0.0250\n",
       "85    0         0      1              0          1           0    0.0458\n",
       "86    0         0      1              0          0           0    0.0202\n",
       "87    0         0      1              0          0           0    0.0676\n",
       "88    0         0      1              0          0           0    0.0165\n",
       "89    0         0      1              0          0           0    0.0036\n",
       "90    0         0      1              1          0           0    0.0665\n",
       "91    0         0      1              1          0           0    0.0438\n",
       "92    0         0      1              1          0           0    0.0423\n",
       "93    0         0      1              1          0           0    0.0466\n",
       "\n",
       "[88 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data cleaning: throw out the outliers\n",
    "\n",
    "baseline_df_clean = baselinedf.drop([20, 36, 38, 44, 53, 57])\n",
    "baseline_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:               Accuracy   No. Observations:                   88\n",
      "Model:                            GLM   Df Residuals:                       82\n",
      "Model Family:                Binomial   Df Model:                            5\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -29.873\n",
      "Date:                Wed, 12 Jun 2019   Deviance:                       2.4687\n",
      "Time:                        16:47:27   Pearson chi2:                     2.45\n",
      "No. Iterations:                     8   Covariance Type:             nonrobust\n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        -1.2916      0.447     -2.892      0.004      -2.167      -0.416\n",
      "VOC               0.1038      0.369      0.282      0.778      -0.619       0.826\n",
      "Toy_data          0.9542      0.394      2.420      0.016       0.182       1.727\n",
      "Kitti            -2.3497      0.617     -3.811      0.000      -3.558      -1.141\n",
      "Augmentations     1.0703      0.530      2.018      0.044       0.031       2.110\n",
      "Batchnorm         0.1368      0.525      0.261      0.794      -0.892       1.166\n",
      "Pretrained        0.4302      0.527      0.817      0.414      -0.602       1.463\n",
      "=================================================================================\n",
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:} &     Accuracy     & \\textbf{  No. Observations:  } &       88    \\\\\n",
      "\\textbf{Model:}         &       GLM        & \\textbf{  Df Residuals:      } &       82    \\\\\n",
      "\\textbf{Model Family:}  &     Binomial     & \\textbf{  Df Model:          } &        5    \\\\\n",
      "\\textbf{Link Function:} &      logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
      "\\textbf{Method:}        &       IRLS       & \\textbf{  Log-Likelihood:    } &   -29.873   \\\\\n",
      "\\textbf{Date:}          & Wed, 12 Jun 2019 & \\textbf{  Deviance:          } &    2.4687   \\\\\n",
      "\\textbf{Time:}          &     16:47:27     & \\textbf{  Pearson chi2:      } &     2.45    \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                       & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$>$$|$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{Intercept}     &      -1.2916  &        0.447     &    -2.892  &         0.004        &       -2.167    &       -0.416     \\\\\n",
      "\\textbf{VOC}           &       0.1038  &        0.369     &     0.282  &         0.778        &       -0.619    &        0.826     \\\\\n",
      "\\textbf{Toy\\_data}     &       0.9542  &        0.394     &     2.420  &         0.016        &        0.182    &        1.727     \\\\\n",
      "\\textbf{Kitti}         &      -2.3497  &        0.617     &    -3.811  &         0.000        &       -3.558    &       -1.141     \\\\\n",
      "\\textbf{Augmentations} &       1.0703  &        0.530     &     2.018  &         0.044        &        0.031    &        2.110     \\\\\n",
      "\\textbf{Batchnorm}     &       0.1368  &        0.525     &     0.261  &         0.794        &       -0.892    &        1.166     \\\\\n",
      "\\textbf{Pretrained}    &       0.4302  &        0.527     &     0.817  &         0.414        &       -0.602    &        1.463     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{Generalized Linear Model Regression Results}\n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "#fit the model with binomial and logistic link function\n",
    "baselinefit = sm.formula.glm( formula='Accuracy~VOC + Toy_data + Kitti + Augmentations + Batchnorm + Pretrained', \n",
    "                         data=baseline_df_clean, \n",
    "                         family=sm.families.Binomial(link=sm.families.links.logit) \n",
    "                       ).fit()\n",
    "print(baselinefit.summary())\n",
    "print(baselinefit.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: VOC \t augmentation: 0 \t batchnorm: 0 \t pretrained: 0 \t mean: 0.108 \t std_dev: 0.008\n",
      "dataset: VOC \t augmentation: 0 \t batchnorm: 0 \t pretrained: 1 \t mean: 0.363 \t std_dev: 0.055\n",
      "dataset: VOC \t augmentation: 0 \t batchnorm: 1 \t pretrained: 0 \t mean: 0.329 \t std_dev: 0.041\n",
      "dataset: VOC \t augmentation: 0 \t batchnorm: 1 \t pretrained: 1 \t mean: 0.341 \t std_dev: 0.017\n",
      "dataset: VOC \t augmentation: 1 \t batchnorm: 0 \t pretrained: 0 \t mean: 0.364 \t std_dev: 0.025\n",
      "dataset: VOC \t augmentation: 1 \t batchnorm: 0 \t pretrained: 1 \t mean: 0.630 \t std_dev: 0.003\n",
      "dataset: VOC \t augmentation: 1 \t batchnorm: 1 \t pretrained: 0 \t mean: 0.568 \t std_dev: 0.002\n",
      "dataset: VOC \t augmentation: 1 \t batchnorm: 1 \t pretrained: 1 \t mean: 0.619 \t std_dev: 0.007\n",
      "dataset: Kitti \t augmentation: 0 \t batchnorm: 0 \t pretrained: 0 \t mean: 0.027 \t std_dev: 0.024\n",
      "dataset: Kitti \t augmentation: 0 \t batchnorm: 0 \t pretrained: 1 \t mean: 0.032 \t std_dev: 0.009\n",
      "dataset: Kitti \t augmentation: 0 \t batchnorm: 1 \t pretrained: 0 \t mean: 0.032 \t std_dev: 0.010\n",
      "dataset: Kitti \t augmentation: 0 \t batchnorm: 1 \t pretrained: 1 \t mean: 0.024 \t std_dev: 0.002\n",
      "dataset: Kitti \t augmentation: 1 \t batchnorm: 0 \t pretrained: 0 \t mean: 0.050 \t std_dev: 0.010\n",
      "dataset: Kitti \t augmentation: 1 \t batchnorm: 0 \t pretrained: 1 \t mean: 0.125 \t std_dev: 0.011\n",
      "dataset: Kitti \t augmentation: 1 \t batchnorm: 1 \t pretrained: 0 \t mean: 0.116 \t std_dev: 0.012\n",
      "dataset: Kitti \t augmentation: 1 \t batchnorm: 1 \t pretrained: 1 \t mean: 0.113 \t std_dev: 0.010\n",
      "dataset: Toy_data \t augmentation: 0 \t batchnorm: 0 \t pretrained: 0 \t mean: 0.487 \t std_dev: 0.060\n",
      "dataset: Toy_data \t augmentation: 0 \t batchnorm: 0 \t pretrained: 1 \t mean: 0.505 \t std_dev: 0.027\n",
      "dataset: Toy_data \t augmentation: 0 \t batchnorm: 1 \t pretrained: 0 \t mean: 0.511 \t std_dev: 0.123\n",
      "dataset: Toy_data \t augmentation: 0 \t batchnorm: 1 \t pretrained: 1 \t mean: 0.474 \t std_dev: 0.053\n",
      "dataset: Toy_data \t augmentation: 1 \t batchnorm: 0 \t pretrained: 0 \t mean: 0.773 \t std_dev: 0.017\n",
      "dataset: Toy_data \t augmentation: 1 \t batchnorm: 0 \t pretrained: 1 \t mean: 0.792 \t std_dev: 0.049\n",
      "dataset: Toy_data \t augmentation: 1 \t batchnorm: 1 \t pretrained: 0 \t mean: 0.613 \t std_dev: 0.128\n",
      "dataset: Toy_data \t augmentation: 1 \t batchnorm: 1 \t pretrained: 1 \t mean: 0.710 \t std_dev: 0.058\n",
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "  Dataset &  Augmentations &  Batchnorm &  Pretrained &   Mean &  Std\\_dev \\\\\n",
      "\\midrule\n",
      "      VOC &              0 &          0 &           0 &  0.108 &    0.008 \\\\\n",
      "      VOC &              0 &          0 &           1 &  0.363 &    0.055 \\\\\n",
      "      VOC &              0 &          1 &           0 &  0.329 &    0.041 \\\\\n",
      "      VOC &              0 &          1 &           1 &  0.341 &    0.017 \\\\\n",
      "      VOC &              1 &          0 &           0 &  0.364 &    0.025 \\\\\n",
      "      VOC &              1 &          0 &           1 &  0.630 &    0.003 \\\\\n",
      "      VOC &              1 &          1 &           0 &  0.568 &    0.002 \\\\\n",
      "      VOC &              1 &          1 &           1 &  0.619 &    0.007 \\\\\n",
      "    Kitti &              0 &          0 &           0 &  0.027 &    0.024 \\\\\n",
      "    Kitti &              0 &          0 &           1 &  0.032 &    0.009 \\\\\n",
      "    Kitti &              0 &          1 &           0 &  0.032 &    0.010 \\\\\n",
      "    Kitti &              0 &          1 &           1 &  0.024 &    0.002 \\\\\n",
      "    Kitti &              1 &          0 &           0 &  0.050 &    0.010 \\\\\n",
      "    Kitti &              1 &          0 &           1 &  0.125 &    0.011 \\\\\n",
      "    Kitti &              1 &          1 &           0 &  0.116 &    0.012 \\\\\n",
      "    Kitti &              1 &          1 &           1 &  0.113 &    0.010 \\\\\n",
      " Toy\\_data &              0 &          0 &           0 &  0.487 &    0.060 \\\\\n",
      " Toy\\_data &              0 &          0 &           1 &  0.505 &    0.027 \\\\\n",
      " Toy\\_data &              0 &          1 &           0 &  0.511 &    0.123 \\\\\n",
      " Toy\\_data &              0 &          1 &           1 &  0.474 &    0.053 \\\\\n",
      " Toy\\_data &              1 &          0 &           0 &  0.773 &    0.017 \\\\\n",
      " Toy\\_data &              1 &          0 &           1 &  0.792 &    0.049 \\\\\n",
      " Toy\\_data &              1 &          1 &           0 &  0.613 &    0.128 \\\\\n",
      " Toy\\_data &              1 &          1 &           1 &  0.710 &    0.058 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a table with the respective means and standard deviations for the categories\n",
    "df = baseline_df_clean\n",
    "datasets = ['VOC', 'Kitti', 'Toy_data']\n",
    "augmentations = [0, 1]\n",
    "batchnorms = [0, 1]\n",
    "pretrained = [0, 1]\n",
    "data = []\n",
    "#df.loc[(df['VOC'] == 1) & (df['Augmentations'] == 1) & (df['Batchnorm'] == 1) & (df['Pretrained'] == 1), 'Accuracy']\n",
    "for d in datasets:\n",
    "    for a in augmentations:\n",
    "        for b in batchnorms:\n",
    "            for p in pretrained:\n",
    "                values = df.loc[(df[d] == 1) & (df['Augmentations'] == a) & (df['Batchnorm'] == b) & (df['Pretrained'] == p), 'Accuracy']\n",
    "                std_dev = np.std(values)\n",
    "                mean = np.mean(values)\n",
    "                print(\"dataset: {} \\t augmentation: {} \\t batchnorm: {} \\t pretrained: {} \\t mean: {:.03f} \\t std_dev: {:.03f}\".format(d,a,b,p, mean, std_dev))\n",
    "                data.append([d,a,b,p, np.around(mean, 3), np.around(std_dev, 3)])\n",
    "        \n",
    "columns = ['Dataset', 'Augmentations', 'Batchnorm', 'Pretrained', 'Mean', 'Std_dev']\n",
    "final_df = pd.DataFrame(data, columns=columns)\n",
    "print(final_df.to_latex(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tests for the invariance datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deformation_data</th>\n",
       "      <th>Rotation_data</th>\n",
       "      <th>Translation_data</th>\n",
       "      <th>Scale_data</th>\n",
       "      <th>Pretrained</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Deformation_data  Rotation_data  Translation_data  Scale_data  Pretrained  \\\n",
       "0                  1              0                 0           0           1   \n",
       "1                  1              0                 0           0           1   \n",
       "2                  1              0                 0           0           1   \n",
       "3                  1              0                 0           0           1   \n",
       "4                  1              0                 0           0           1   \n",
       "5                  1              0                 0           0           0   \n",
       "6                  1              0                 0           0           0   \n",
       "7                  1              0                 0           0           0   \n",
       "8                  1              0                 0           0           0   \n",
       "9                  1              0                 0           0           0   \n",
       "10                 0              1                 0           0           1   \n",
       "11                 0              1                 0           0           1   \n",
       "12                 0              1                 0           0           1   \n",
       "13                 0              1                 0           0           1   \n",
       "14                 0              1                 0           0           1   \n",
       "15                 0              1                 0           0           1   \n",
       "16                 0              1                 0           0           0   \n",
       "17                 0              1                 0           0           0   \n",
       "18                 0              1                 0           0           0   \n",
       "19                 0              1                 0           0           0   \n",
       "20                 0              1                 0           0           0   \n",
       "21                 0              1                 0           0           0   \n",
       "22                 0              0                 1           0           1   \n",
       "23                 0              0                 1           0           1   \n",
       "24                 0              0                 1           0           1   \n",
       "25                 0              0                 1           0           1   \n",
       "26                 0              0                 1           0           1   \n",
       "27                 0              0                 1           0           0   \n",
       "28                 0              0                 1           0           0   \n",
       "29                 0              0                 1           0           0   \n",
       "30                 0              0                 1           0           0   \n",
       "31                 0              0                 1           0           0   \n",
       "32                 0              0                 0           1           1   \n",
       "33                 0              0                 0           1           1   \n",
       "34                 0              0                 0           1           1   \n",
       "35                 0              0                 0           1           1   \n",
       "36                 0              0                 0           1           1   \n",
       "37                 0              0                 0           1           0   \n",
       "38                 0              0                 0           1           0   \n",
       "39                 0              0                 0           1           0   \n",
       "40                 0              0                 0           1           0   \n",
       "41                 0              0                 0           1           0   \n",
       "\n",
       "    Accuracy  \n",
       "0     0.9237  \n",
       "1     0.8462  \n",
       "2     0.8947  \n",
       "3     0.9047  \n",
       "4     0.9088  \n",
       "5     0.9237  \n",
       "6     0.9302  \n",
       "7     0.9267  \n",
       "8     0.9320  \n",
       "9     0.9293  \n",
       "10    0.6568  \n",
       "11    0.6259  \n",
       "12    0.6226  \n",
       "13    0.6486  \n",
       "14    0.5803  \n",
       "15    0.5989  \n",
       "16    0.6568  \n",
       "17    0.6316  \n",
       "18    0.6302  \n",
       "19    0.6247  \n",
       "20    0.6317  \n",
       "21    0.6335  \n",
       "22    0.0005  \n",
       "23    0.0011  \n",
       "24    0.0019  \n",
       "25    0.0024  \n",
       "26    0.0016  \n",
       "27    0.0005  \n",
       "28    0.0009  \n",
       "29    0.0011  \n",
       "30    0.0035  \n",
       "31    0.0009  \n",
       "32    0.6324  \n",
       "33    0.6422  \n",
       "34    0.6395  \n",
       "35    0.6395  \n",
       "36    0.6327  \n",
       "37    0.6324  \n",
       "38    0.6467  \n",
       "39    0.6485  \n",
       "40    0.6477  \n",
       "41    0.6447  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load and show\n",
    "invariantdf = pd.read_csv('invariant_data.csv', delimiter=',')\n",
    "invariantdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:               Accuracy   No. Observations:                   42\n",
      "Model:                            GLM   Df Residuals:                       37\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -11.790\n",
      "Date:                Wed, 12 Jun 2019   Deviance:                     0.086250\n",
      "Time:                        16:46:44   Pearson chi2:                   0.0930\n",
      "No. Iterations:                     9   Covariance Type:             nonrobust\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           -0.5830      1.724     -0.338      0.735      -3.962       2.796\n",
      "Deformation_data     2.9682      1.903      1.560      0.119      -0.761       6.697\n",
      "Rotation_data        1.1550      1.756      0.658      0.511      -2.287       4.597\n",
      "Scale_data           1.2074      1.770      0.682      0.495      -2.261       4.676\n",
      "Translation_data    -5.9137      6.678     -0.886      0.376     -19.002       7.175\n",
      "Pretrained          -0.0920      0.822     -0.112      0.911      -1.704       1.520\n",
      "====================================================================================\n",
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}    &     Accuracy     & \\textbf{  No. Observations:  } &       42    \\\\\n",
      "\\textbf{Model:}            &       GLM        & \\textbf{  Df Residuals:      } &       37    \\\\\n",
      "\\textbf{Model Family:}     &     Binomial     & \\textbf{  Df Model:          } &        4    \\\\\n",
      "\\textbf{Link Function:}    &      logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
      "\\textbf{Method:}           &       IRLS       & \\textbf{  Log-Likelihood:    } &   -11.790   \\\\\n",
      "\\textbf{Date:}             & Wed, 12 Jun 2019 & \\textbf{  Deviance:          } &  0.086250   \\\\\n",
      "\\textbf{Time:}             &     16:46:44     & \\textbf{  Pearson chi2:      } &   0.0930    \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                           & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$>$$|$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{Intercept}         &      -0.5830  &        1.724     &    -0.338  &         0.735        &       -3.962    &        2.796     \\\\\n",
      "\\textbf{Deformation\\_data} &       2.9682  &        1.903     &     1.560  &         0.119        &       -0.761    &        6.697     \\\\\n",
      "\\textbf{Rotation\\_data}    &       1.1550  &        1.756     &     0.658  &         0.511        &       -2.287    &        4.597     \\\\\n",
      "\\textbf{Scale\\_data}       &       1.2074  &        1.770     &     0.682  &         0.495        &       -2.261    &        4.676     \\\\\n",
      "\\textbf{Translation\\_data} &      -5.9137  &        6.678     &    -0.886  &         0.376        &      -19.002    &        7.175     \\\\\n",
      "\\textbf{Pretrained}        &      -0.0920  &        0.822     &    -0.112  &         0.911        &       -1.704    &        1.520     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{Generalized Linear Model Regression Results}\n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "#fit the model with binomial and logistic link function\n",
    "invariantfit = sm.formula.glm( formula='Accuracy~Deformation_data  + Rotation_data + Scale_data + Translation_data + Pretrained', \n",
    "                         data=invariantdf, \n",
    "                         family=sm.families.Binomial(link=sm.families.links.logit) \n",
    "                       ).fit()\n",
    "print(invariantfit.summary())\n",
    "print(invariantfit.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: Deformation_data \t pretrained: 0 \t mean: 0.928 \t std_dev: 0.003\n",
      "dataset: Deformation_data \t pretrained: 1 \t mean: 0.896 \t std_dev: 0.026\n",
      "dataset: Rotation_data \t pretrained: 0 \t mean: 0.635 \t std_dev: 0.010\n",
      "dataset: Rotation_data \t pretrained: 1 \t mean: 0.622 \t std_dev: 0.026\n",
      "dataset: Translation_data \t pretrained: 0 \t mean: 0.001 \t std_dev: 0.001\n",
      "dataset: Translation_data \t pretrained: 1 \t mean: 0.002 \t std_dev: 0.001\n",
      "dataset: Scale_data \t pretrained: 0 \t mean: 0.644 \t std_dev: 0.006\n",
      "dataset: Scale_data \t pretrained: 1 \t mean: 0.637 \t std_dev: 0.004\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "          Dataset &  Pretrained &   Mean &  Std\\_dev \\\\\n",
      "\\midrule\n",
      " Deformation\\_data &           0 &  0.928 &    0.003 \\\\\n",
      " Deformation\\_data &           1 &  0.896 &    0.026 \\\\\n",
      "    Rotation\\_data &           0 &  0.635 &    0.010 \\\\\n",
      "    Rotation\\_data &           1 &  0.622 &    0.026 \\\\\n",
      " Translation\\_data &           0 &  0.001 &    0.001 \\\\\n",
      " Translation\\_data &           1 &  0.002 &    0.001 \\\\\n",
      "       Scale\\_data &           0 &  0.644 &    0.006 \\\\\n",
      "       Scale\\_data &           1 &  0.637 &    0.004 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a table with the respective means and standard deviations for the categories\n",
    "df = invariantdf\n",
    "datasets = ['Deformation_data', 'Rotation_data', 'Translation_data', 'Scale_data']\n",
    "pretrained = [0, 1]\n",
    "data = []\n",
    "#df.loc[(df['VOC'] == 1) & (df['Augmentations'] == 1) & (df['Batchnorm'] == 1) & (df['Pretrained'] == 1), 'Accuracy']\n",
    "for d in datasets:\n",
    "    for p in pretrained:\n",
    "        values = df.loc[(df[d] == 1) & (df['Pretrained'] == p), 'Accuracy']\n",
    "        std_dev = np.std(values)\n",
    "        mean = np.mean(values)\n",
    "        print(\"dataset: {} \\t pretrained: {} \\t mean: {:.03f} \\t std_dev: {:.03f}\".format(d,p, mean, std_dev))\n",
    "        data.append([d,p, np.around(mean, 3), np.around(std_dev, 3)])\n",
    "\n",
    "columns = ['Dataset', 'Pretrained', 'Mean', 'Std_dev']\n",
    "final_df = pd.DataFrame(data, columns=columns)\n",
    "print(final_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 sequential scattering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VOC</th>\n",
       "      <th>Kitti</th>\n",
       "      <th>Toy_data</th>\n",
       "      <th>Scale_data</th>\n",
       "      <th>Rotation_data</th>\n",
       "      <th>Deformation_data</th>\n",
       "      <th>Translation_data</th>\n",
       "      <th>Pretrained</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VOC  Kitti  Toy_data  Scale_data  Rotation_data  Deformation_data  \\\n",
       "0     1      0         0           0              0                 0   \n",
       "1     1      0         0           0              0                 0   \n",
       "2     1      0         0           0              0                 0   \n",
       "3     1      0         0           0              0                 0   \n",
       "4     0      1         0           0              0                 0   \n",
       "5     0      1         0           0              0                 0   \n",
       "6     0      1         0           0              0                 0   \n",
       "7     0      1         0           0              0                 0   \n",
       "8     0      1         0           0              0                 0   \n",
       "9     0      1         0           0              0                 0   \n",
       "10    0      0         1           0              0                 0   \n",
       "11    0      0         1           0              0                 0   \n",
       "12    0      0         1           0              0                 0   \n",
       "13    0      0         1           0              0                 0   \n",
       "14    0      0         1           0              0                 0   \n",
       "15    0      0         1           0              0                 0   \n",
       "16    0      0         0           1              0                 0   \n",
       "17    0      0         0           1              0                 0   \n",
       "18    0      0         0           1              0                 0   \n",
       "19    0      0         0           1              0                 0   \n",
       "20    0      0         0           1              0                 0   \n",
       "21    0      0         0           1              0                 0   \n",
       "22    0      0         0           0              1                 0   \n",
       "23    0      0         0           0              1                 0   \n",
       "24    0      0         0           0              1                 0   \n",
       "25    0      0         0           0              1                 0   \n",
       "26    0      0         0           0              1                 0   \n",
       "27    0      0         0           0              1                 0   \n",
       "28    0      0         0           0              0                 1   \n",
       "29    0      0         0           0              0                 1   \n",
       "30    0      0         0           0              0                 1   \n",
       "31    0      0         0           0              0                 1   \n",
       "32    0      0         0           0              0                 1   \n",
       "33    0      0         0           0              0                 1   \n",
       "34    0      0         0           0              0                 0   \n",
       "35    0      0         0           0              0                 0   \n",
       "36    0      0         0           0              0                 0   \n",
       "37    0      0         0           0              0                 0   \n",
       "38    0      0         0           0              0                 0   \n",
       "39    0      0         0           0              0                 0   \n",
       "\n",
       "    Translation_data  Pretrained  Accuracy  \n",
       "0                  0           1    0.4692  \n",
       "1                  0           1    0.3940  \n",
       "2                  0           0    0.3952  \n",
       "3                  0           0    0.4034  \n",
       "4                  0           1    0.0750  \n",
       "5                  0           1    0.0815  \n",
       "6                  0           1    0.0756  \n",
       "7                  0           0    0.1110  \n",
       "8                  0           0    0.1100  \n",
       "9                  0           0    0.1082  \n",
       "10                 0           1    0.8168  \n",
       "11                 0           1    0.8179  \n",
       "12                 0           1    0.8181  \n",
       "13                 0           0    0.8308  \n",
       "14                 0           0    0.8314  \n",
       "15                 0           0    0.8302  \n",
       "16                 0           1    0.6434  \n",
       "17                 0           1    0.6378  \n",
       "18                 0           1    0.6429  \n",
       "19                 0           0    0.6455  \n",
       "20                 0           0    0.6460  \n",
       "21                 0           0    0.6457  \n",
       "22                 0           1    0.6385  \n",
       "23                 0           1    0.6005  \n",
       "24                 0           1    0.7394  \n",
       "25                 0           0    0.5986  \n",
       "26                 0           0    0.5701  \n",
       "27                 0           0    0.6004  \n",
       "28                 0           1    0.9294  \n",
       "29                 0           1    0.9280  \n",
       "30                 0           1    0.9286  \n",
       "31                 0           0    0.9343  \n",
       "32                 0           0    0.9340  \n",
       "33                 0           0    0.9312  \n",
       "34                 1           1    0.8574  \n",
       "35                 1           1    0.8553  \n",
       "36                 1           1    0.5868  \n",
       "37                 1           0    0.8574  \n",
       "38                 1           0    0.8567  \n",
       "39                 1           0    0.8574  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load and show\n",
    "sequentialdf = pd.read_csv('scattering_sequential.csv', delimiter=',')\n",
    "sequentialdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:               Accuracy   No. Observations:                   40\n",
      "Model:                            GLM   Df Residuals:                       32\n",
      "Model Family:                Binomial   Df Model:                            7\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -13.468\n",
      "Date:                Fri, 14 Jun 2019   Deviance:                      0.45398\n",
      "Time:                        16:16:06   Pearson chi2:                    0.504\n",
      "No. Iterations:                     6   Covariance Type:             nonrobust\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            0.5339      0.515      1.037      0.300      -0.475       1.543\n",
      "VOC                 -0.8504      0.959     -0.887      0.375      -2.729       1.029\n",
      "Kitti               -2.7801      1.273     -2.184      0.029      -5.275      -0.285\n",
      "Toy_data             1.0364      1.005      1.031      0.303      -0.934       3.007\n",
      "Deformation_data     2.0923      1.446      1.447      0.148      -0.742       4.927\n",
      "Rotation_data        0.0003      0.825      0.000      1.000      -1.616       1.617\n",
      "Scale_data           0.0821      0.832      0.099      0.921      -1.549       1.713\n",
      "Translation_data     0.9533      0.983      0.970      0.332      -0.973       2.880\n",
      "Pretrained          -0.0502      0.789     -0.064      0.949      -1.596       1.495\n",
      "====================================================================================\n",
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}    &     Accuracy     & \\textbf{  No. Observations:  } &       40    \\\\\n",
      "\\textbf{Model:}            &       GLM        & \\textbf{  Df Residuals:      } &       32    \\\\\n",
      "\\textbf{Model Family:}     &     Binomial     & \\textbf{  Df Model:          } &        7    \\\\\n",
      "\\textbf{Link Function:}    &      logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
      "\\textbf{Method:}           &       IRLS       & \\textbf{  Log-Likelihood:    } &   -13.468   \\\\\n",
      "\\textbf{Date:}             & Fri, 14 Jun 2019 & \\textbf{  Deviance:          } &   0.45398   \\\\\n",
      "\\textbf{Time:}             &     16:16:06     & \\textbf{  Pearson chi2:      } &    0.504    \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                           & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$>$$|$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{Intercept}         &       0.5339  &        0.515     &     1.037  &         0.300        &       -0.475    &        1.543     \\\\\n",
      "\\textbf{VOC}               &      -0.8504  &        0.959     &    -0.887  &         0.375        &       -2.729    &        1.029     \\\\\n",
      "\\textbf{Kitti}             &      -2.7801  &        1.273     &    -2.184  &         0.029        &       -5.275    &       -0.285     \\\\\n",
      "\\textbf{Toy\\_data}         &       1.0364  &        1.005     &     1.031  &         0.303        &       -0.934    &        3.007     \\\\\n",
      "\\textbf{Deformation\\_data} &       2.0923  &        1.446     &     1.447  &         0.148        &       -0.742    &        4.927     \\\\\n",
      "\\textbf{Rotation\\_data}    &       0.0003  &        0.825     &     0.000  &         1.000        &       -1.616    &        1.617     \\\\\n",
      "\\textbf{Scale\\_data}       &       0.0821  &        0.832     &     0.099  &         0.921        &       -1.549    &        1.713     \\\\\n",
      "\\textbf{Translation\\_data} &       0.9533  &        0.983     &     0.970  &         0.332        &       -0.973    &        2.880     \\\\\n",
      "\\textbf{Pretrained}        &      -0.0502  &        0.789     &    -0.064  &         0.949        &       -1.596    &        1.495     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{Generalized Linear Model Regression Results}\n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "#fit the model with binomial and logistic link function\n",
    "sequentialfit = sm.formula.glm( formula='Accuracy~VOC + Kitti + Toy_data + Deformation_data  + Rotation_data + Scale_data + Translation_data + Pretrained', \n",
    "                         data=sequentialdf, \n",
    "                         family=sm.families.Binomial(link=sm.families.links.logit) \n",
    "                       ).fit()\n",
    "print(sequentialfit.summary())\n",
    "print(sequentialfit.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: VOC \t pretrained: 0 \t mean: 0.399 \t std_dev: 0.004\n",
      "dataset: VOC \t pretrained: 1 \t mean: 0.432 \t std_dev: 0.038\n",
      "dataset: Kitti \t pretrained: 0 \t mean: 0.110 \t std_dev: 0.001\n",
      "dataset: Kitti \t pretrained: 1 \t mean: 0.077 \t std_dev: 0.003\n",
      "dataset: Toy_data \t pretrained: 0 \t mean: 0.831 \t std_dev: 0.000\n",
      "dataset: Toy_data \t pretrained: 1 \t mean: 0.818 \t std_dev: 0.001\n",
      "dataset: Deformation_data \t pretrained: 0 \t mean: 0.933 \t std_dev: 0.001\n",
      "dataset: Deformation_data \t pretrained: 1 \t mean: 0.929 \t std_dev: 0.001\n",
      "dataset: Rotation_data \t pretrained: 0 \t mean: 0.590 \t std_dev: 0.014\n",
      "dataset: Rotation_data \t pretrained: 1 \t mean: 0.659 \t std_dev: 0.059\n",
      "dataset: Translation_data \t pretrained: 0 \t mean: 0.857 \t std_dev: 0.000\n",
      "dataset: Translation_data \t pretrained: 1 \t mean: 0.767 \t std_dev: 0.127\n",
      "dataset: Scale_data \t pretrained: 0 \t mean: 0.646 \t std_dev: 0.000\n",
      "dataset: Scale_data \t pretrained: 1 \t mean: 0.641 \t std_dev: 0.003\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "          Dataset &  Pretrained &   Mean &  Std\\_dev \\\\\n",
      "\\midrule\n",
      "              VOC &           0 &  0.399 &    0.004 \\\\\n",
      "              VOC &           1 &  0.432 &    0.038 \\\\\n",
      "            Kitti &           0 &  0.110 &    0.001 \\\\\n",
      "            Kitti &           1 &  0.077 &    0.003 \\\\\n",
      "         Toy\\_data &           0 &  0.831 &    0.000 \\\\\n",
      "         Toy\\_data &           1 &  0.818 &    0.001 \\\\\n",
      " Deformation\\_data &           0 &  0.933 &    0.001 \\\\\n",
      " Deformation\\_data &           1 &  0.929 &    0.001 \\\\\n",
      "    Rotation\\_data &           0 &  0.590 &    0.014 \\\\\n",
      "    Rotation\\_data &           1 &  0.659 &    0.059 \\\\\n",
      " Translation\\_data &           0 &  0.857 &    0.000 \\\\\n",
      " Translation\\_data &           1 &  0.767 &    0.127 \\\\\n",
      "       Scale\\_data &           0 &  0.646 &    0.000 \\\\\n",
      "       Scale\\_data &           1 &  0.641 &    0.003 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a table with the respective means and standard deviations for the categories\n",
    "df = sequentialdf\n",
    "datasets = ['VOC', 'Kitti', 'Toy_data', 'Deformation_data', 'Rotation_data', 'Translation_data', 'Scale_data']\n",
    "pretrained = [0, 1]\n",
    "data = []\n",
    "#df.loc[(df['VOC'] == 1) & (df['Augmentations'] == 1) & (df['Batchnorm'] == 1) & (df['Pretrained'] == 1), 'Accuracy']\n",
    "for d in datasets:\n",
    "    for p in pretrained:\n",
    "        values = df.loc[(df[d] == 1) & (df['Pretrained'] == p), 'Accuracy']\n",
    "        std_dev = np.std(values)\n",
    "        mean = np.mean(values)\n",
    "        print(\"dataset: {} \\t pretrained: {} \\t mean: {:.03f} \\t std_dev: {:.03f}\".format(d,p, mean, std_dev))\n",
    "        data.append([d,p, np.around(mean, 3), np.around(std_dev, 3)])\n",
    "\n",
    "columns = ['Dataset', 'Pretrained', 'Mean', 'Std_dev']\n",
    "final_df = pd.DataFrame(data, columns=columns)\n",
    "print(final_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 parallel scattering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VOC</th>\n",
       "      <th>Kitti</th>\n",
       "      <th>Toy_data</th>\n",
       "      <th>Deformation_data</th>\n",
       "      <th>Rotation_data</th>\n",
       "      <th>Translation_data</th>\n",
       "      <th>Scale_data</th>\n",
       "      <th>Pretrained</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VOC  Kitti  Toy_data  Deformation_data  Rotation_data  Translation_data  \\\n",
       "0     1      0         0                 0              0                 0   \n",
       "1     1      0         0                 0              0                 0   \n",
       "2     0      1         0                 0              0                 0   \n",
       "3     0      1         0                 0              0                 0   \n",
       "4     0      0         1                 0              0                 0   \n",
       "5     0      0         1                 0              0                 0   \n",
       "6     0      0         0                 1              0                 0   \n",
       "7     0      0         0                 1              0                 0   \n",
       "8     0      0         0                 0              1                 0   \n",
       "9     0      0         0                 0              1                 0   \n",
       "10    0      0         0                 0              0                 1   \n",
       "11    0      0         0                 0              0                 1   \n",
       "12    0      0         0                 0              0                 0   \n",
       "13    0      0         0                 0              0                 0   \n",
       "\n",
       "    Scale_data  Pretrained  Accuracy  \n",
       "0            0           1    0.4760  \n",
       "1            0           0    0.1456  \n",
       "2            0           1    0.1048  \n",
       "3            0           0    0.0415  \n",
       "4            0           1    0.8037  \n",
       "5            0           0    0.7449  \n",
       "6            0           1    0.9117  \n",
       "7            0           0    0.8997  \n",
       "8            0           1    0.6133  \n",
       "9            0           0    0.6766  \n",
       "10           0           1    0.8459  \n",
       "11           0           0    0.8414  \n",
       "12           1           1    0.6412  \n",
       "13           1           0    0.6415  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load and show\n",
    "paralleldf = pd.read_csv('scattering_parallel.csv', delimiter=',')\n",
    "paralleldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:               Accuracy   No. Observations:                   14\n",
      "Model:                            GLM   Df Residuals:                        6\n",
      "Model Family:                Binomial   Df Model:                            7\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -4.7429\n",
      "Date:                Sun, 16 Jun 2019   Deviance:                      0.24234\n",
      "Time:                        12:27:21   Pearson chi2:                    0.234\n",
      "No. Iterations:                     5   Covariance Type:             nonrobust\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            0.2234      0.858      0.260      0.794      -1.458       1.904\n",
      "VOC                 -1.2057      1.484     -0.812      0.417      -4.114       1.703\n",
      "Kitti               -2.9562      2.450     -1.207      0.228      -7.758       1.846\n",
      "Toy_data             0.8385      1.605      0.522      0.601      -2.307       3.984\n",
      "Deformation_data     1.8721      2.195      0.853      0.394      -2.431       6.175\n",
      "Rotation_data        0.1984      1.439      0.138      0.890      -2.622       3.019\n",
      "Scale_data           0.1826      1.437      0.127      0.899      -2.633       2.999\n",
      "Translation_data     1.2936      1.809      0.715      0.475      -2.252       4.839\n",
      "Pretrained           0.3595      1.338      0.269      0.788      -2.263       2.982\n",
      "====================================================================================\n",
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}    &     Accuracy     & \\textbf{  No. Observations:  } &       14    \\\\\n",
      "\\textbf{Model:}            &       GLM        & \\textbf{  Df Residuals:      } &        6    \\\\\n",
      "\\textbf{Model Family:}     &     Binomial     & \\textbf{  Df Model:          } &        7    \\\\\n",
      "\\textbf{Link Function:}    &      logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
      "\\textbf{Method:}           &       IRLS       & \\textbf{  Log-Likelihood:    } &   -4.7429   \\\\\n",
      "\\textbf{Date:}             & Sun, 16 Jun 2019 & \\textbf{  Deviance:          } &   0.24234   \\\\\n",
      "\\textbf{Time:}             &     12:27:21     & \\textbf{  Pearson chi2:      } &    0.234    \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                           & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$>$$|$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{Intercept}         &       0.2234  &        0.858     &     0.260  &         0.794        &       -1.458    &        1.904     \\\\\n",
      "\\textbf{VOC}               &      -1.2057  &        1.484     &    -0.812  &         0.417        &       -4.114    &        1.703     \\\\\n",
      "\\textbf{Kitti}             &      -2.9562  &        2.450     &    -1.207  &         0.228        &       -7.758    &        1.846     \\\\\n",
      "\\textbf{Toy\\_data}         &       0.8385  &        1.605     &     0.522  &         0.601        &       -2.307    &        3.984     \\\\\n",
      "\\textbf{Deformation\\_data} &       1.8721  &        2.195     &     0.853  &         0.394        &       -2.431    &        6.175     \\\\\n",
      "\\textbf{Rotation\\_data}    &       0.1984  &        1.439     &     0.138  &         0.890        &       -2.622    &        3.019     \\\\\n",
      "\\textbf{Scale\\_data}       &       0.1826  &        1.437     &     0.127  &         0.899        &       -2.633    &        2.999     \\\\\n",
      "\\textbf{Translation\\_data} &       1.2936  &        1.809     &     0.715  &         0.475        &       -2.252    &        4.839     \\\\\n",
      "\\textbf{Pretrained}        &       0.3595  &        1.338     &     0.269  &         0.788        &       -2.263    &        2.982     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{Generalized Linear Model Regression Results}\n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "#fit the model with binomial and logistic link function\n",
    "parallelfit = sm.formula.glm( formula='Accuracy~VOC + Kitti + Toy_data + Deformation_data  + Rotation_data + Scale_data + Translation_data + Pretrained', \n",
    "                         data=paralleldf, \n",
    "                         family=sm.families.Binomial(link=sm.families.links.logit) \n",
    "                       ).fit()\n",
    "print(parallelfit.summary())\n",
    "print(parallelfit.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: VOC \t pretrained: 0 \t mean: 0.146 \t std_dev: 0.000\n",
      "dataset: VOC \t pretrained: 1 \t mean: 0.476 \t std_dev: 0.000\n",
      "dataset: Kitti \t pretrained: 0 \t mean: 0.042 \t std_dev: 0.000\n",
      "dataset: Kitti \t pretrained: 1 \t mean: 0.105 \t std_dev: 0.000\n",
      "dataset: Toy_data \t pretrained: 0 \t mean: 0.745 \t std_dev: 0.000\n",
      "dataset: Toy_data \t pretrained: 1 \t mean: 0.804 \t std_dev: 0.000\n",
      "dataset: Deformation_data \t pretrained: 0 \t mean: 0.900 \t std_dev: 0.000\n",
      "dataset: Deformation_data \t pretrained: 1 \t mean: 0.912 \t std_dev: 0.000\n",
      "dataset: Rotation_data \t pretrained: 0 \t mean: 0.677 \t std_dev: 0.000\n",
      "dataset: Rotation_data \t pretrained: 1 \t mean: 0.613 \t std_dev: 0.000\n",
      "dataset: Translation_data \t pretrained: 0 \t mean: 0.841 \t std_dev: 0.000\n",
      "dataset: Translation_data \t pretrained: 1 \t mean: 0.846 \t std_dev: 0.000\n",
      "dataset: Scale_data \t pretrained: 0 \t mean: 0.641 \t std_dev: 0.000\n",
      "dataset: Scale_data \t pretrained: 1 \t mean: 0.641 \t std_dev: 0.000\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "          Dataset &  Pretrained &   Mean &  Std\\_dev \\\\\n",
      "\\midrule\n",
      "              VOC &           0 &  0.146 &      0.0 \\\\\n",
      "              VOC &           1 &  0.476 &      0.0 \\\\\n",
      "            Kitti &           0 &  0.042 &      0.0 \\\\\n",
      "            Kitti &           1 &  0.105 &      0.0 \\\\\n",
      "         Toy\\_data &           0 &  0.745 &      0.0 \\\\\n",
      "         Toy\\_data &           1 &  0.804 &      0.0 \\\\\n",
      " Deformation\\_data &           0 &  0.900 &      0.0 \\\\\n",
      " Deformation\\_data &           1 &  0.912 &      0.0 \\\\\n",
      "    Rotation\\_data &           0 &  0.677 &      0.0 \\\\\n",
      "    Rotation\\_data &           1 &  0.613 &      0.0 \\\\\n",
      " Translation\\_data &           0 &  0.841 &      0.0 \\\\\n",
      " Translation\\_data &           1 &  0.846 &      0.0 \\\\\n",
      "       Scale\\_data &           0 &  0.642 &      0.0 \\\\\n",
      "       Scale\\_data &           1 &  0.641 &      0.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a table with the respective means and standard deviations for the categories\n",
    "df = paralleldf\n",
    "datasets = ['VOC', 'Kitti', 'Toy_data', 'Deformation_data', 'Rotation_data', 'Translation_data', 'Scale_data']\n",
    "pretrained = [0, 1]\n",
    "data = []\n",
    "#df.loc[(df['VOC'] == 1) & (df['Augmentations'] == 1) & (df['Batchnorm'] == 1) & (df['Pretrained'] == 1), 'Accuracy']\n",
    "for d in datasets:\n",
    "    for p in pretrained:\n",
    "        values = df.loc[(df[d] == 1) & (df['Pretrained'] == p), 'Accuracy']\n",
    "        std_dev = np.std(values)\n",
    "        mean = np.mean(values)\n",
    "        print(\"dataset: {} \\t pretrained: {} \\t mean: {:.03f} \\t std_dev: {:.03f}\".format(d,p, mean, std_dev))\n",
    "        data.append([d,p, np.around(mean, 3), np.around(std_dev, 3)])\n",
    "\n",
    "columns = ['Dataset', 'Pretrained', 'Mean', 'Std_dev']\n",
    "final_df = pd.DataFrame(data, columns=columns)\n",
    "print(final_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kitti</th>\n",
       "      <th>VOC</th>\n",
       "      <th>Toy_data</th>\n",
       "      <th>Deformation_data</th>\n",
       "      <th>Rotation_data</th>\n",
       "      <th>Translation_data</th>\n",
       "      <th>Scale_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.7920</td>\n",
       "      <td>0.9280</td>\n",
       "      <td>0.6350</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.6440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.8310</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>0.6590</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.6460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.8037</td>\n",
       "      <td>0.9117</td>\n",
       "      <td>0.6766</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.6415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Kitti    VOC  Toy_data  Deformation_data  Rotation_data  Translation_data  \\\n",
       "0  0.1250  0.630    0.7920            0.9280         0.6350            0.0020   \n",
       "1  0.1100  0.432    0.8310            0.9330         0.6590            0.8570   \n",
       "2  0.1048  0.476    0.8037            0.9117         0.6766            0.8459   \n",
       "\n",
       "   Scale_data  \n",
       "0      0.6440  \n",
       "1      0.6460  \n",
       "2      0.6415  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load and show\n",
    "comparisondf = pd.read_csv('comparison.csv', delimiter=',')\n",
    "comparisondf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  Standard SSD &  Sequential Scattering &  Parallel Scattering \\\\\n",
      "\\midrule\n",
      "Kitti            &         0.125 &                  0.110 &               0.1048 \\\\\n",
      "VOC              &         0.630 &                  0.432 &               0.4760 \\\\\n",
      "Toy\\_data         &         0.792 &                  0.831 &               0.8037 \\\\\n",
      "Deformation\\_data &         0.928 &                  0.933 &               0.9117 \\\\\n",
      "Rotation\\_data    &         0.635 &                  0.659 &               0.6766 \\\\\n",
      "Translation\\_data &         0.002 &                  0.857 &               0.8459 \\\\\n",
      "Scale\\_data       &         0.644 &                  0.646 &               0.6415 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fancy table\n",
    "comparisondf.rename(index={0:'Standard SSD',1:'Sequential Scattering', 2:'Parallel Scattering'}, inplace=True)\n",
    "comparisondfT = comparisondf.T\n",
    "print(comparisondfT.to_latex(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fancy plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15,4)\n",
    "plt.plot(comparisondf.loc['Standard SSD'], linestyle='--', marker='o', color=\"blue\", label=\"Standard SSD\")\n",
    "plt.plot(comparisondf.loc['Sequential Scattering'], linestyle='--', marker='v', color=\"red\", label=\"Sequential Scattering\")\n",
    "plt.plot(comparisondf.loc['Parallel Scattering'], linestyle='--', marker='^', color=\"green\", label=\"Parallel Scattering\")\n",
    "plt.legend()\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of the Architectures')\n",
    "plt.savefig('comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scattering parallel: mean=1.499 \t std=0.002\n",
      "sequential scattering: mean=0.178 \t std=0.004\n",
      "normal: mean=0.236 \t std=0.004\n"
     ]
    }
   ],
   "source": [
    "#TIMINGS:\n",
    "\n",
    "scattering_parallel = [1.4894, 1.4930, 1.4955, 1.4959, 1.4999, 1.4968, 1.5008, 1.4978, 1.4987, 1.4994, \n",
    "                       1.4981, 1.4968, 1.4971, 1.4998, 1.4970, 1.4986, 1.5014, 1.4976, 1.4985, 1.4984,\n",
    "                       1.4964, 1.4981, 1.4962, 1.5008, 1.4969, 1.5001, 1.4992, 1.4984, 1.4989, 1.5001,\n",
    "                       1.4980, 1.5013, 1.4993, 1.5012, 1.4980, 1.4980, 1.5017, 1.4977, 1.5017, 1.4978,\n",
    "                       1.4978, 1.5020, 1.4967, 1.4982, 1.4986, 1.4984, 1.4991, 1.4989, 1.4994, 1.5000, \n",
    "                       1.5002, 1.4986, 1.4983, 1.4988, 1.4998, 1.4976, 1.4969, 1.5012, 1.4995, 1.4972, \n",
    "                       1.4994, 1.5017, 1.4997, 1.5002, 1.5010, 1.4955, 1.4982, 1.4990, 1.5000, 1.5004, \n",
    "                       1.5002, 1.4976, 1.4981, 1.4997, 1.4970, 1.4990, 1.5003, 1.4987, 1.4981, 1.4988,\n",
    "                       1.4998, 1.4991, 1.5000, 1.4999, 1.4992, 1.4980, 1.4980, 1.4957, 1.4994, 1.5017,\n",
    "                       1.4999, 1.4958, 1.4982, 1.5011, 1.4983, 1.4989, 1.4981, 1.4966, 1.4990, 1.5009]\n",
    "print(\"scattering parallel: mean={:.03f} \\t std={:.03f}\".format(np.mean(scattering_parallel), np.std(scattering_parallel)))\n",
    "\n",
    "scattering_sequential = [0.1739, 0.1778, 0.1765, 0.2032, 0.1740, 0.1788, 0.1766, 0.1870, 0.1756, 0.1738,\n",
    "                         0.1757, 0.1747, 0.1854, 0.1746, 0.1746, 0.1824, 0.1770, 0.1766, 0.1772, 0.1769,\n",
    "                         0.1765, 0.1750, 0.1753, 0.1858, 0.1775, 0.1766, 0.1820, 0.1804, 0.1758, 0.1842,\n",
    "                         0.1750, 0.1772, 0.1749, 0.1756, 0.1757, 0.1789, 0.1791, 0.1748, 0.1822, 0.1766,\n",
    "                         0.1790, 0.1806, 0.1767, 0.1770, 0.1764, 0.1757, 0.1745, 0.1780, 0.1800, 0.1794,\n",
    "                         0.1757, 0.1748, 0.1850, 0.1775, 0.1771, 0.1754, 0.1769, 0.1765, 0.1781, 0.1810,\n",
    "                         0.1798, 0.1755, 0.1761, 0.1856, 0.1749, 0.1859, 0.1752, 0.1761, 0.1758, 0.1840,\n",
    "                         0.1844, 0.1824, 0.1775, 0.1762, 0.1877, 0.1763, 0.1754, 0.1876, 0.1834, 0.1761, \n",
    "                         0.1750, 0.1742, 0.1745, 0.1749, 0.1828, 0.1778, 0.1775, 0.1863, 0.1771, 0.1805,\n",
    "                         0.1762, 0.1782, 0.1857, 0.1789, 0.1769, 0.1760, 0.1788, 0.1764, 0.1788, 0.1803]\n",
    "\n",
    "print(\"sequential scattering: mean={:.03f} \\t std={:.03f}\".format(np.mean(scattering_sequential), np.std(scattering_sequential)))\n",
    "\n",
    "normal = [0.2331, 0.2343, 0.2323, 0.2359, 0.2340, 0.2328, 0.2344, 0.2329, 0.2333, 0.2308,\n",
    "          0.2332, 0.2343, 0.2343, 0.2346, 0.2313, 0.2637, 0.2352, 0.2360, 0.2340, 0.2356,\n",
    "          0.2357, 0.2328, 0.2355, 0.2358, 0.2339, 0.2362, 0.2362, 0.2333, 0.2362, 0.2355,\n",
    "          0.2475, 0.2381, 0.2346, 0.2347, 0.2335, 0.2362, 0.2342, 0.2338, 0.2360, 0.2340,\n",
    "          0.2340, 0.2358, 0.2359, 0.2340, 0.2357, 0.2357, 0.2323, 0.2537, 0.2353, 0.2370,\n",
    "          0.2348, 0.2362, 0.2355, 0.2340, 0.2357, 0.2363, 0.2338, 0.2346, 0.2362, 0.2338,\n",
    "          0.2408, 0.2332, 0.2363, 0.2395, 0.2359, 0.2361, 0.2343, 0.2364, 0.2354, 0.2351,\n",
    "          0.2359, 0.2356, 0.2350, 0.2318, 0.2368, 0.2339, 0.2321, 0.2356, 0.2359, 0.2398,\n",
    "          0.2361, 0.2367, 0.2345, 0.2349, 0.2362, 0.2346, 0.2328, 0.2332, 0.2344, 0.2358,\n",
    "          0.2347, 0.2341, 0.2329, 0.2366, 0.2337, 0.2445, 0.2360, 0.2363, 0.2344, 0.2452]\n",
    "\n",
    "print(\"normal: mean={:.03f} \\t std={:.03f}\".format(np.mean(normal), np.std(normal)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# small data and short training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toy_data_small</th>\n",
       "      <th>VOC</th>\n",
       "      <th>twentyfivek</th>\n",
       "      <th>fivek</th>\n",
       "      <th>standard</th>\n",
       "      <th>sequential_scattering</th>\n",
       "      <th>parallel_scattering</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Toy_data_small  VOC  twentyfivek  fivek  standard  sequential_scattering  \\\n",
       "0                1    0            1      0         1                      0   \n",
       "1                1    0            1      0         1                      0   \n",
       "2                1    0            1      0         1                      0   \n",
       "3                1    0            1      0         0                      1   \n",
       "4                1    0            1      0         0                      1   \n",
       "5                1    0            1      0         0                      1   \n",
       "6                1    0            1      0         0                      0   \n",
       "7                1    0            1      0         0                      0   \n",
       "8                1    0            1      0         0                      0   \n",
       "9                1    0            0      1         1                      0   \n",
       "10               1    0            0      1         1                      0   \n",
       "11               1    0            0      1         1                      0   \n",
       "12               1    0            0      1         0                      1   \n",
       "13               1    0            0      1         0                      1   \n",
       "14               1    0            0      1         0                      1   \n",
       "15               1    0            0      1         0                      0   \n",
       "16               1    0            0      1         0                      0   \n",
       "17               1    0            0      1         0                      0   \n",
       "18               0    1            1      0         1                      0   \n",
       "19               0    1            1      0         1                      0   \n",
       "20               0    1            1      0         1                      0   \n",
       "21               0    1            1      0         0                      1   \n",
       "22               0    1            1      0         0                      1   \n",
       "23               0    1            1      0         0                      1   \n",
       "24               0    1            1      0         0                      0   \n",
       "25               0    1            1      0         0                      0   \n",
       "26               0    1            1      0         0                      0   \n",
       "27               0    1            0      1         1                      0   \n",
       "28               0    1            0      1         1                      0   \n",
       "29               0    1            0      1         1                      0   \n",
       "30               0    1            0      1         0                      1   \n",
       "31               0    1            0      1         0                      1   \n",
       "32               0    1            0      1         0                      1   \n",
       "33               0    1            0      1         0                      0   \n",
       "34               0    1            0      1         0                      0   \n",
       "35               0    1            0      1         0                      0   \n",
       "\n",
       "    parallel_scattering  Accuracy  \n",
       "0                     0    0.6202  \n",
       "1                     0    0.6303  \n",
       "2                     0    0.6407  \n",
       "3                     0    0.7613  \n",
       "4                     0    0.7621  \n",
       "5                     0    0.7542  \n",
       "6                     1    0.4220  \n",
       "7                     1    0.4166  \n",
       "8                     1    0.3942  \n",
       "9                     0    0.0374  \n",
       "10                    0    0.0388  \n",
       "11                    0    0.0538  \n",
       "12                    0    0.1115  \n",
       "13                    0    0.0941  \n",
       "14                    0    0.1583  \n",
       "15                    1    0.0043  \n",
       "16                    1    0.0024  \n",
       "17                    1    0.0024  \n",
       "18                    0    0.3305  \n",
       "19                    0    0.3158  \n",
       "20                    0    0.3034  \n",
       "21                    0    0.0573  \n",
       "22                    0    0.0579  \n",
       "23                    0    0.0452  \n",
       "24                    1    0.0121  \n",
       "25                    1    0.0140  \n",
       "26                    1    0.0129  \n",
       "27                    0    0.0257  \n",
       "28                    0    0.0247  \n",
       "29                    0    0.0240  \n",
       "30                    0    0.0060  \n",
       "31                    0    0.0058  \n",
       "32                    0    0.0208  \n",
       "33                    1    0.0042  \n",
       "34                    1    0.0043  \n",
       "35                    1    0.0043  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load and show\n",
    "smalldatadf = pd.read_csv('small_data_experiments.csv', delimiter=',')\n",
    "smalldatadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:               Accuracy   No. Observations:                   36\n",
      "Model:                            GLM   Df Residuals:                       31\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -8.0310\n",
      "Date:                Wed, 12 Jun 2019   Deviance:                       1.3209\n",
      "Time:                        16:43:30   Pearson chi2:                     1.27\n",
      "No. Iterations:                     7   Covariance Type:             nonrobust\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -1.0483      0.356     -2.947      0.003      -1.745      -0.351\n",
      "Toy_data_small            0.6860      0.549      1.250      0.211      -0.390       1.762\n",
      "VOC                      -1.7343      0.706     -2.457      0.014      -3.118      -0.351\n",
      "twentyfivek               1.1156      0.637      1.751      0.080      -0.133       2.364\n",
      "fivek                    -2.1638      0.881     -2.457      0.014      -3.890      -0.437\n",
      "standard                  0.2188      0.735      0.298      0.766      -1.222       1.660\n",
      "sequential_scattering     0.0583      0.740      0.079      0.937      -1.392       1.509\n",
      "parallel_scattering      -1.3253      0.887     -1.494      0.135      -3.064       0.413\n",
      "=========================================================================================\n",
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}         &     Accuracy     & \\textbf{  No. Observations:  } &       36    \\\\\n",
      "\\textbf{Model:}                 &       GLM        & \\textbf{  Df Residuals:      } &       31    \\\\\n",
      "\\textbf{Model Family:}          &     Binomial     & \\textbf{  Df Model:          } &        4    \\\\\n",
      "\\textbf{Link Function:}         &      logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
      "\\textbf{Method:}                &       IRLS       & \\textbf{  Log-Likelihood:    } &   -8.0310   \\\\\n",
      "\\textbf{Date:}                  & Wed, 12 Jun 2019 & \\textbf{  Deviance:          } &    1.3209   \\\\\n",
      "\\textbf{Time:}                  &     16:43:30     & \\textbf{  Pearson chi2:      } &     1.27    \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                                & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$>$$|$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{Intercept}              &      -1.0483  &        0.356     &    -2.947  &         0.003        &       -1.745    &       -0.351     \\\\\n",
      "\\textbf{Toy\\_data\\_small}       &       0.6860  &        0.549     &     1.250  &         0.211        &       -0.390    &        1.762     \\\\\n",
      "\\textbf{VOC}                    &      -1.7343  &        0.706     &    -2.457  &         0.014        &       -3.118    &       -0.351     \\\\\n",
      "\\textbf{twentyfivek}            &       1.1156  &        0.637     &     1.751  &         0.080        &       -0.133    &        2.364     \\\\\n",
      "\\textbf{fivek}                  &      -2.1638  &        0.881     &    -2.457  &         0.014        &       -3.890    &       -0.437     \\\\\n",
      "\\textbf{standard}               &       0.2188  &        0.735     &     0.298  &         0.766        &       -1.222    &        1.660     \\\\\n",
      "\\textbf{sequential\\_scattering} &       0.0583  &        0.740     &     0.079  &         0.937        &       -1.392    &        1.509     \\\\\n",
      "\\textbf{parallel\\_scattering}   &      -1.3253  &        0.887     &    -1.494  &         0.135        &       -3.064    &        0.413     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{Generalized Linear Model Regression Results}\n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "#fit the model with binomial and logistic link function\n",
    "small_data_fit = sm.formula.glm( formula='Accuracy ~ Toy_data_small + VOC + twentyfivek + fivek + standard + sequential_scattering + parallel_scattering', \n",
    "                         data=smalldatadf, \n",
    "                         family=sm.families.Binomial(link=sm.families.links.logit) \n",
    "                       ).fit()\n",
    "print(small_data_fit.summary())\n",
    "print(small_data_fit.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: Toy_data_small \t length: 25k \t network: standard \t mean: 0.630 \t std_dev: 0.008\n",
      "dataset: Toy_data_small \t length: 25k \t network: sequential_scattering \t mean: 0.759 \t std_dev: 0.004\n",
      "dataset: Toy_data_small \t length: 25k \t network: parallel_scattering \t mean: 0.411 \t std_dev: 0.012\n",
      "dataset: Toy_data_small \t length: 5k \t network: standard \t mean: 0.043 \t std_dev: 0.007\n",
      "dataset: Toy_data_small \t length: 5k \t network: sequential_scattering \t mean: 0.121 \t std_dev: 0.027\n",
      "dataset: Toy_data_small \t length: 5k \t network: parallel_scattering \t mean: 0.003 \t std_dev: 0.001\n",
      "dataset: VOC \t length: 25k \t network: standard \t mean: 0.317 \t std_dev: 0.011\n",
      "dataset: VOC \t length: 25k \t network: sequential_scattering \t mean: 0.053 \t std_dev: 0.006\n",
      "dataset: VOC \t length: 25k \t network: parallel_scattering \t mean: 0.013 \t std_dev: 0.001\n",
      "dataset: VOC \t length: 5k \t network: standard \t mean: 0.025 \t std_dev: 0.001\n",
      "dataset: VOC \t length: 5k \t network: sequential_scattering \t mean: 0.011 \t std_dev: 0.007\n",
      "dataset: VOC \t length: 5k \t network: parallel_scattering \t mean: 0.004 \t std_dev: 0.000\n",
      "\\begin{tabular}{lllrr}\n",
      "\\toprule\n",
      "        Dataset & epochs &           network type &   Mean &  Std\\_dev \\\\\n",
      "\\midrule\n",
      " Toy\\_data\\_small &    25k &               standard &  0.630 &    0.008 \\\\\n",
      " Toy\\_data\\_small &    25k &  sequential\\_scattering &  0.759 &    0.004 \\\\\n",
      " Toy\\_data\\_small &    25k &    parallel\\_scattering &  0.411 &    0.012 \\\\\n",
      " Toy\\_data\\_small &     5k &               standard &  0.043 &    0.007 \\\\\n",
      " Toy\\_data\\_small &     5k &  sequential\\_scattering &  0.121 &    0.027 \\\\\n",
      " Toy\\_data\\_small &     5k &    parallel\\_scattering &  0.003 &    0.001 \\\\\n",
      "            VOC &    25k &               standard &  0.317 &    0.011 \\\\\n",
      "            VOC &    25k &  sequential\\_scattering &  0.053 &    0.006 \\\\\n",
      "            VOC &    25k &    parallel\\_scattering &  0.013 &    0.001 \\\\\n",
      "            VOC &     5k &               standard &  0.025 &    0.001 \\\\\n",
      "            VOC &     5k &  sequential\\_scattering &  0.011 &    0.007 \\\\\n",
      "            VOC &     5k &    parallel\\_scattering &  0.004 &    0.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a table with the respective means and standard deviations for the categories\n",
    "df = smalldatadf\n",
    "datasets = ['Toy_data_small', 'VOC']\n",
    "length = ['twentyfivek', 'fivek']\n",
    "network = ['standard', 'sequential_scattering', 'parallel_scattering']\n",
    "data = []\n",
    "#df.loc[(df['VOC'] == 1) & (df['Augmentations'] == 1) & (df['Batchnorm'] == 1) & (df['Pretrained'] == 1), 'Accuracy']\n",
    "for d in datasets:\n",
    "    for l in length:\n",
    "        for n in network:\n",
    "            values = df.loc[(df[d] == 1) & (df[l] == 1) & (df[n] ==1), 'Accuracy']\n",
    "            std_dev = np.std(values)\n",
    "            mean = np.mean(values)\n",
    "            l_string = '25k' if l == 'twentyfivek' else '5k'\n",
    "            print(\"dataset: {} \\t length: {} \\t network: {} \\t mean: {:.03f} \\t std_dev: {:.03f}\".format(d,l_string,n, mean, std_dev))\n",
    "            data.append([d,l_string,n, np.around(mean, 3), np.around(std_dev, 3)])\n",
    "\n",
    "columns = ['Dataset', 'epochs', 'network type', 'Mean', 'Std_dev']\n",
    "final_df = pd.DataFrame(data, columns=columns)\n",
    "print(final_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
